{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import coremltools as ct\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing according to MobileNetV2 recomendations\n",
    "preprocess_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandAugment(3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.RandomHorizontalFlip(0.5), # 53% com augmentation\n",
    "    #transforms.RandomRotation(45),\n",
    "    #transforms.GaussianBlur(3),\n",
    "    #transforms.ColorJitter(),\n",
    "    #transforms.RandomPerspective(),\n",
    "    #transforms.RandomEqualize(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "preprocess_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actinic-keratosis', 'basal-cell-carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented-benign-keratosis', 'seborrheic-keratosis', 'squamous-cell-carcinoma', 'vascular-lesion']\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "data_dir = \"dataset_cancer\"\n",
    "sets = ['Train', 'Test']\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='dataset_cancer/Train', transform=preprocess_train)\n",
    "\n",
    "# ImageFolder\n",
    "test_dataset =  torchvision.datasets.ImageFolder(root='dataset_cancer/Test', transform=preprocess_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=24, shuffle=True, num_workers=8)\n",
    "\n",
    "# DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=True, num_workers=8)\n",
    "\n",
    "# sanity check\n",
    "class_names = train_dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNetModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=3e-4, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dim = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.shufflenet_v2_x0_5(\n",
    "            weights=models.ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # get output from last layer\n",
    "        in_features = self.feature_extractor.fc.in_features\n",
    "        \n",
    "        # remove the last layer (classifier)\n",
    "        self.feature_extractor.fc = torch.nn.Identity()\n",
    "\n",
    "        if transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "                \n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature_extractor(x)\n",
    "        return self.classifier(out)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "            batch, labels = batch[0], batch[1]\n",
    "            # prediction\n",
    "            out = self.forward(batch)\n",
    "\n",
    "            # loss and accuracy\n",
    "            loss = self.criterion(out, labels)\n",
    "            acc = self.accuracy(out, labels)\n",
    "\n",
    "            self.log(\"shuffle/train/loss\", loss)        \n",
    "            self.log(\"shuffle/train/acc\", acc)\n",
    "\n",
    "            return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        batch, labels = batch[0], batch[1]\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        loss = self.criterion(out, labels)      \n",
    "        acc = self.accuracy(out, labels)\n",
    "\n",
    "        self.log(\"shuffle/test/loss\", loss)        \n",
    "        self.log(\"shuffle/test/acc\", acc)\n",
    "        \n",
    "\n",
    "        return {\"loss\": loss, \"outputs\": out, \"labels\": labels}\n",
    "\n",
    "    # def test_epoch_end(self, outputs):\n",
    "    #     loss = torch.stack([x['loss']for x in outputs]).mean()\n",
    "    #     output = torch.cat([x['outputs']for x in outputs], dim=0)\n",
    "\n",
    "    #     labels = torch.cat([x['labels'] for x in outputs], dim=0)\n",
    "\n",
    "    #     self.log(\"test/loss\", loss)\n",
    "    #     acc = self.accuracy(output, labels)\n",
    "    #     self.log(\"test/acc\", acc)\n",
    "\n",
    "    #     self.test_gts = labels\n",
    "\n",
    "    #     self.test_output = output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=3e-4, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dim = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.mobilenet_v2(\n",
    "            weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        # remove the last layer (classifier)\n",
    "        self.feature_extractor.classifier = torch.nn.Identity()\n",
    "\n",
    "        if transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            \n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # get the output size of last layer            \n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "        # add last layer with correct output\n",
    "        self.classifier = nn.Linear(n_sizes, num_classes)\n",
    "\n",
    "        # loss and accuracy functions\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy()\n",
    "    \n",
    "    # returns the size of the output tensor going into the Linear layer from the conv block.\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.view(batch_size, -1).size(1)\n",
    "\n",
    "        return n_size\n",
    "    \n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x) # rede pre treinada\n",
    "        x = x.view(x.size(0), -1) # \n",
    "        x = self.classifier(x) # classificador\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        batch, labels = batch[0], batch[1]\n",
    "        # prediction\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        # loss and accuracy\n",
    "        loss = self.criterion(out, labels)\n",
    "        acc = self.accuracy(out, labels)\n",
    "\n",
    "        self.log(\"mobile/train/loss\", loss)        \n",
    "        self.log(\"mobile/train/acc\", acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        batch, labels = batch[0], batch[1]\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        loss = self.criterion(out, labels)      \n",
    "\n",
    "        acc = self.accuracy(out, labels)\n",
    "        self.log(\"mobile/test/loss\", loss)        \n",
    "        self.log(\"mobile/test/acc\", acc)\n",
    "\n",
    "        return {\"loss\": loss, \"outputs\": out, \"labels\": labels}\n",
    "\n",
    "    # def test_epoch_end(self, outputs):\n",
    "    #     loss = torch.stack([x['loss']for x in outputs]).mean()\n",
    "    #     output = torch.cat([x['outputs']for x in outputs], dim=0)\n",
    "\n",
    "    #     labels = torch.cat([x['labels'] for x in outputs], dim=0)\n",
    "\n",
    "    #     self.log(\"test/loss\", loss)\n",
    "    #     acc = self.accuracy(output, labels)\n",
    "    #     self.log(\"test/acc\", acc)\n",
    "\n",
    "    #     self.test_gts = labels\n",
    "\n",
    "    #     self.test_output = output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os modelos\n",
    "shuffle_model = ShuffleNetModel((3,256, 256), 9, transfer=False)\n",
    "mobile_model = MobileNetModel((3,256, 256), 9, transfer=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer_shuffle.fit(shuffle_model, train_loader)\n",
    "trainer_shuffle.test(shuffle_model, test_loader)\n",
    "\n",
    "torch.save(shuffle_model.state_dict(), \"shuffle_model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando os Trainers\n",
    "trainer_mobile = pl.Trainer(max_epochs=20)\n",
    "trainer_shuffle = pl.Trainer(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando, testando  e salvando os modelos \n",
    "trainer_mobile.fit(mobile_model, train_loader)\n",
    "trainer_mobile.test(mobile_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mobile_model.state_dict(), \"mobile_model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_shuffle.fit(shuffle_model, train_loader)\n",
    "trainer_shuffle.test(shuffle_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shuffle_model.state_dict(), \"shuffle_model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace the model\n",
    "example_input = torch.rand(1,3,256,256)\n",
    "traced_mobile_model = torch.jit.trace(mobile_model, example_input)\n",
    "\n",
    "mobile_model_converted = ct.convert(\n",
    "    traced_mobile_model, \n",
    "    inputs=[ct.TensorType(shape=example_input.shape)])\n",
    "mobile_model_converted.save(\"mobile_model.mlmodel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dlProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c5f5e62ed960257033dd11cb8cd90a5c18544cc323975609b6a42bdd40b0f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
